\documentclass[a4paper,11pt]{article}

% set up sensible margins (same as for cssethesis)
\usepackage[paper=a4paper,left=30mm,width=150mm,top=25mm,bottom=25mm]{geometry}
\usepackage{setspace}               % This is used in the title page
\usepackage{graphicx}               % This is used to load the crest in the title page
\usepackage{poltakmacros}           % Personal macros included in file 'poltakmacros.sty'
\usepackage{enumitem}               % For nested enum lists
\usepackage[font={small}]{caption}
\usepackage[hidelinks]{hyperref}
\usepackage{url}


\author{Jonathan Poltak Samosir}
\title{Honours Research Proposal}

\begin{document}

% Set up a title page
\thispagestyle{empty} % no page number on very first page
% Use roman numerals for page numbers initially
\renewcommand{\thepage}{\roman{page}}

\begin{spacing}{1.5}
\begin{center}
{\Large \bfseries
Clayton School of Information Technology\\
Monash University}

\vspace*{30mm}

\includegraphics[width=5cm]{img/MonashCrest.pdf}

\vspace*{15mm}

{\large \bfseries
Honours Research Proposal --- Semester 2, 2014
}

\vspace*{10mm}

{\LARGE \bfseries
A pipeline for the preprocessing and storage of heterogeneous big data [WORKING TITLE]
}

\vspace*{20mm}

{\large \bfseries
Jonathan Poltak Samosir [2271 3603]

\vspace*{20mm}

Supervisors: \parbox[t]{50mm}{\mbox{Dr Maria Indrawan-Santiago}\\Dr Pari Delir Haghighi}
}

\end{center}
\end{spacing}

\newpage

\tableofcontents

\newpage
% Now reset page number counter,and switch to arabic numerals for remaining page numbers
\setcounter{page}{1}
\renewcommand{\thepage}{\arabic{page}}



% Start of content

\section{Introduction} % (fold)
\label{sec:introduction}

Currently, as a society, we are generating very large amounts of data from a large range of different sources. These
sources include scientific experiments, such as the Australian Synchrotron~\cite{web:synchrotron} and The Large Hadron
Collider~\cite{web:LHC}, companies, such as Amazon~\cite{web:Amazon}, and also data generated by end users of products,
such as social networks. The rate of data that is being generated is constantly increasing, presenting major challenges
when it comes to the storage and processing of that data~\cite{bohlouli_towards_2013}. This is what is often referred to
as ``Big Data''. Out of all of this data we are faced with, often only specific parts of the data are of use for given
purposes. Hence rather than attempting to store all the new data that is being generating, often what is done, in both
academia and industry associated with big data, is the realtime processing and analysis of incoming data streams.

There are currently numerous realtime data processing frameworks that are in development and in production use, both in
industry and academia. Examples of these realtime data processing frameworks include the widely used Storm
project~\cite{web:Storm} developed at BackType and Twitter, Inc., and also the up-and-coming Spark Streaming
project~\cite{web:SparkStreaming} developed at UC Berkeley's AMPLab~\cite{web:UCBerkelyAMCLab}, both of which are open-
source projects. While there are a growing number of these projects being developed, often these projects are designed
with a particular type of data in mind, or to facilitate a particular type of data processing. For example, the before
mentioned Spark Streaming project, along with its mother project, Spark~\cite{web:Spark}, was designed for highly
parallelised data with the use-case in mind of processing data in-memory using highly iterative machine learning
algorithms related to data analytics~\cite{liu_survey_2014}.

Given these, occasionally ``narrow'', use-cases for existing data stream processing frameworks, challenges are faced in
supporting the variations in both data types and processing requirements for data processing applications. In this
research project, we aim to study the different characteristics of the data processing requirements based on the
different characteristics of the data types. The knowledge found of these characteristics will be compared with the
properties of existing solutions for big data processing.

What we propose in this document is an entire heterogeneous data processing pipeline that will facilitate the following
tasks, in sequence:

\begin{enumerate}
  \item Take in streams of data from various sources.
  \item Aggregate similar types of data.
  \item Process the data appropriately, depending on its type and the application.
  \item Store the results of the data processing on an appropriate storage medium.
\end{enumerate}

From this research project, we aim to produce a set of recommendations on choosing the various components of the
pipeline, along with recommendations on how the components should be interconnected. To complement this, we also aim to
produce a design template on the deployment of the pipeline in a cloud environment. This will be expanded on in further
detail in~\sectref{sec:expected_outcomes}.

This document will be structured as follows:\\
Discussion of the existing research and work done into this area will be
touched on in~\sectref{sec:research_context}. Our research questions, along with an outline of what we will be doing
will be outlined in~\sectref{sec:objectives}. The methodology used to achieve the deliverables of this project will be
discussed in~\sectref{sec:research_design}. Finally, we will conclude with an overview, in~\sectref{sec:expected_outcomes},
of what the expected outcomes of this project will be, along with the greater contributions this project will give back,
in the way of technological, disciplinary, and societal contributions.

% section introduction (end)



\section{Research Context} % (fold)
\label{sec:research_context}

\subsection{Big data} % (fold)
\label{sub:big_data}

Big data, as explained previously, is becoming commonplace in both industry and academia. Everyday companies are finding
that they are generating too much data and that their traditional database management system (DMBS) solutions cannot
scale to the epic proportions needed to handle this data in an efficient and robust manner~\cite{marz2013principles}.
Hence, companies and academics alike have started looking at alternative solutions designed with the goal of handling
these massive datasets.

The most popular solution for this problem, up until recently, has been the MapReduce model of programming along with
some type of scalable distributed storage system~\cite{bifet_mining_2013}. The MapReduce model was started at Google,
Inc.\@ with their own proprietary implementation along with their proprietary distributed file system, known as the Google
File System (GFS). Without going into the low-level details of MapReduce and GFS, the use of this solution at Google
allowed the company to easily handle all the data that was coming into their servers, and perform the necessary
processing operations that was needed at the time~\cite{ghemawat_google_2003}~\cite{dean_mapreduce:_2008}.

% subsection big_data (end)

\subsection{Apache Hadoop} % (fold)
\label{sub:apache_hadoop}

From the success of MapReduce usage combined with GFS at Google, the open-source community responded swiftly with the
development of the Apache Hadoop framework. Hadoop originally offered an open-source implementation of MapReduce and
their own open-source distributed file system known as the Hadoop Distributed File System
(HDFS)~\cite{shvachko_hadoop_2010}.

Hadoop soon became the subject of mass-adoption in both industry and academia, being deployed at a fast rate.
Development of the Hadoop framework also grew at a fast rate, with new applications related to HDFS and MapReduce being
built on top of Hadoop, greatly benefiting the ecosystem as a whole. Some of these applications grew into widely adopted
systems in their own right. For example, Hadoop applications such as Apache Pig~\cite{gates_building_2009} and
Hive~\cite{thusoo_hive_2010} allow for easy querying and manipulation of data stored on HDFS, both coming with the
addition of their own ``SQL-like'' query languages~\cite{olston_pig_2008}.

Additionally, as further non-MapReduce model applications became of interest to the Hadoop community, Hadoop soon
developed a further abstraction on top of the underlying resources (in most cases, HDFS). The goal of this was to
facilitate the development and deployment of many different applications, varying in use-case, which could be run on the
Hadoop ecosystem, without forcing developers to fit their application into the MapReduce model. This development was
known as Apache Hadoop YARN:\@ Yet Another Resource Negotiator, which can be thought of as an operating system sitting
atop of the available Hadoop resources~\cite{vavilapalli_apache_2013}. The abstraction YARN provides facilitated the
development of much more advanced, and non-MapReduce technologies which have since become widely used parts of the
Hadoop ecosystem~\cite{harrison_hadoops_2012}.

% subsection apache_hadoop (end)

\subsection{Realtime data processing} % (fold)
\label{sub:realtime_data_processing}

One of the major limitations of Hadoop, and the MapReduce model in general, soon became obvious:\@ MapReduce was designed
with the goal of being able to process batches of data, hence, given Hadoop's dominance, batched data processing was the
focal point of the entire distributed data processing domain~\cite{kamburugamuve_survey_2014}. Essentially, batched data
processing is where data gets collected first into large enough batches before being processed all-at-once. The point of
processing in such a way is so there would be less overheads than attempting to process each individual datum as it
arrives. For a lot of use-cases this was, and still is, fine as there were no other drawbacks apart from a high level of
latency between the stages of when the data arrives and when it gets processed. However, for other applications, such as
stock trading, sensor monitoring, and web traffic processing, a more low-latency, realtime solution was
needed~\cite{kamburugamuve_survey_2014}.

Soon, many solutions, with different use-cases and design goals, were developed in the area of distributed stream
processing systems (DSPS). Given the Hadoop ecosystem that was already widely adopted, most of these DSPSs were built
upon the still new YARN layer, ensuring overall compatibility with the Hadoop ecosystem, and the underlying HDFS. Some
examples of such projects include the beforementioned Apache Storm, currently being used at Twitter,
Inc.~\cite{toshniwal_stormtwitter_2014}, among many other companies. Also up-and-coming projects, such as Apache Samza
which is a recently open-sourced project, currently being used in production at LinkedIn Corporation~\cite{web:Samza}.

% subsection realtime_data_processing (end)

\subsection{The future} % (fold)
\label{sub:the_future}

While the overall area of big data processing has definitely been moving at a very fast pace in the last decade, the
area focused on realtime big data processing is still relatively young and shows much potential for further growth in
the way of research. As of writing, there are a considerable amount DSPS technologies available and in active
development, and are fast gaining adoption in industry.

While the various DSPS technologies available offer much needed realtime data stream processing functionality, it is
rather confusing for the end-user to differentiate between which of the technologies would be best given the users'
specific use-case and the class of data they are working with. Currently, real time data stream processing is presented
in most of the major DSPS technologies as a collection of steps, such as Apache Storm's topologies being made up of the
``bolt'' processing step abstraction along with Apache Samza's processing model being made up of their ``task''
abstractions~\cite{kamburugamuve_survey_2014}. Hence, with the existence of various DSPS technologies within the Hadoop
ecosystem and elsewhere, and the idea of data stream processing as a collection of processing steps, the DSPS components
can be set up in a pipeline topology for general data processing. The idea behind this pipeline being that each step
along the way in the pipeline can be made up of loosely related DSPS technologies, depending on the class of data needed
to be processed. There is no fixed pipeline; the general model should be DSPS-agnostic.

There has recently been an attempt at introducing a DSPS-agnostic architecture, known as the Lambda
architecture~\cite{marz2013principles}, that is currently gaining traction in the academic
community~\cite{islam_cloud_2014}~\cite{liu_survey_2014}.

We propose looking into the Lambda architecture, and similar attempts, as inspirations for our system that will allow
for processing recommendations for given data classes and the dynamic construction of a heterogeneous data processing
pipeline.

% subsection the_future (end)

% section research_context (end)



\section{Objectives} % (fold)
\label{sec:objectives}

\subsection{Research questions} % (fold)
\label{sub:research_questions}

The following research questions will be the main focus of our project:

\begin{enumerate}
  \item What classification methods can we use to best classify arbitrary types of data?
  \item How can we formulate processing recommendations based upon the specific class of data identified for a particular dataset?
  \item How can existing data stream processing solutions be used or be altered for use within our project?
\end{enumerate}

Of course, from these preliminary questions, we will probably have to decompose them into a number of workable units.

Additionally, after answering each of these preliminary research questions, we will want to properly implement the
theoretical discoveries from each stage. We do this with the goal of achieving some deployable pipeline that can be then
be used in the testing and overall evaluation stages.

Note that the methodology behind how we are going to answer these questions is given in~\sectref{sec:methodology}.

% subsection research_questions (end)


\subsection{Research aims} % (fold)
\label{sub:research_aims}

The main aim or goal of this research project is to develop a set of recommendations that define exactly how certain
types, or classes, of data should be processed. These recommendations can then be used to specify particular software
that can be used to make up a realtime data processing pipeline. The purpose of the pipeline being to take data from
arbitrary sources, process it in some specified way, then store the needed results on some storage medium~\eg{}, HDFS.

Relating back to the first research question, to achieve the goal of developing a set of processing recommendations for
specific classes of data, we first aim to discover and implement some kind of classification technique for the purpose of
classifying different types of data. To implement the entire pipeline, this classification stage will need to happen early
on, hence will be one of our first aims we attempt to satisfy.

By the end of the project, we aim to have a proof-of-concept implementation of the pipeline working on the National
eResearch Collaboration Tools and Resources (NeCTAR) cloud~\cite{web:Nectar}. Further details regarding NeCTAR can be
found in~\sectref{sec:methodology} and~\sectref{sub:special_facilities_required}. Further details can be found on the
implementation of the pipeline in~\sectref{sec:expected_outcomes}.

We aim to be able to automate the formulation of some NeCTAR-compatible scripts, based on the data processing
recommendations. These scripts will be generated with the aim of enabling NeCTAR end-users to be able to deploy a
specific variation of the pipeline on their NeCTAR instances. The scripts, and the pipelines they produce, will vary in
which technologies make up the pipeline for their given use-case. The use-case being the specific class of data that
they are attempting to process.

Further detail on the project deliverables based upon these aims can be found in~\sectref{sec:expected_outcomes}.

% subsection research_aims (end)

% section objectives (end)



\section{Methodology} % (fold)
\label{sec:methodology}

\subsection{Use of NeCTAR cloud services} % (fold)
\label{sub:use_of_nectar_cloud_services}

One of the key parts of our research methodology will be the applied use of the National eResearch Collaboration Tools
and Resources cloud (NeCTAR)~\cite{web:Nectar}. Access to this cloud will facilitate the majority of applied work that
happens in this project, including the testing of existing big data stream processing technologies along with the
evaluation of our project's technical outcomes. It will also serve as the target platform for the implementation and
deployment of our pipeline.

To give a brief overview of NeCTAR, NeCTAR is a \$47 million (AUD) project funded by the Australian government to
facilitate Australian eResearch through providing shared Cloud infrastructures, among other
facilities~\cite{sinnott_towards_2011}.

As of writing, we have requested two NeCTAR Cloud instances for this project's use. The instances having 16 shared
cores, 6400 hours of processing time, and one terabyte of shared volume storage. Going by initial estimates, these
requested resources should suffice for the scope of this research project. These resources are further touched on
in~\sectref{sub:special_facilities_required}.

% subsection use_of_nectar_cloud_services (end)

\subsection{Data classification method} % (fold)
\label{sub:data_classification_method}

For the research methodology surrounding the data classification method, we will look at ways of employing various
statistical classification techniques from the area of machine learning. A quantitative study of different statistical
classification techniques will have to be performed in the early stages of the project. For this initial study, we may
look at different classification methods, such as support vector machines, or naive Bayes classifiers, and perform an
evaluation on the results that they produce, given specific classes of test data.

From preliminary research for this project, we have discovered that there is a rather small set of possible DSPS
technologies currently available to choose from. Hence, regardless of the number of different classes of data, multiple
different classes may have to be given the same processing recommendations, effectively limiting the number of data
classes. This makes the task of employing a data classification method much more simple in the context of this project.

% subsection data_classification_method (end)

\subsection{Data processing recommendations} % (fold)
\label{sub:data_processing_recommendations}

As stated in our second research question, in~\sectref{sub:research_questions}, we will formulate specific processing
recommendations for each given class of data. An example of these recommendations would be, for data displaying
properties of that of belonging to a graph data class, we would recommend the usage of the GraphX abstraction on top of
the Apache Spark DSPS for processing, given GraphX's suitability for the processing of graph
data~\cite{DBLP:journals/corr/XinCDGFS14}.

We will provide mappings from specific data classes to processing recommendations, such as is shown in the earlier example.

% subsection data_processing_recommendations (end)

% section methodology (end)

\section{Research Design} % (fold)
\label{sec:research_design}

\subsection{Proposed thesis chapter headings} % (fold)
\label{sub:proposed_thesis_chapter_headings}

The proposed structure of the thesis is as follows:

\begin{enumerate}
  \item Introduction
  \begin{enumerate}[label*=\arabic*.]
    \item Overview
    \item Background
    \item Research problem
    \item Research questions
    \item Research scope
    \item Conclusion and thesis structure
  \end{enumerate}
  \item Literature Review
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Definition of terms
    \item Big data in industry and academia
    \item Batch data processing
    \item Overview of batch data processing technologies
    \item Realtime data processing
    \item Overview of realtime data processing technologies
    \item Disruptive research in big data
    \item Conclusion
  \end{enumerate}
  \item Streaming Data Preprocessing Pipeline Model
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Need for preprocessing pipeline
    \item Overview of pipeline
    \item Usage of pipeline
    \item Conclusion
  \end{enumerate}
  \item Research Method and Implementation
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Chosen research method
    \item Data classification method
    \item Data processing technologies for pipeline
    \item Implementation of pipeline in NeCTAR cloud
    \item Formulation of pipeline recommendations
    \item Conclusion
  \end{enumerate}
  \item Discussion and Evaluation
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Further methods for data classification
    \item Future of big data research
    \item Evaluation of project
    \item Conclusion
  \end{enumerate}
  \item Conclusion
  \begin{enumerate}[label*=\arabic*.]
    \item Overview
    \item Research contributions
    \item Research limitations
    \item Future research
  \end{enumerate}
  \item Reference List
  \item Appendices
\end{enumerate}

% subsection proposed_thesis_chapter_headings (end)

\subsection{Timeline} % (fold)
\label{sub:timeline}

The following is a preliminary estimated timeline of the proposed research project:

\begin{center}
\begin{tabular}{ |l|l| }
  \hline
  \textbf{Task / Deliverable}           & \textbf{Deadline} \\ \hline
  First meeting with supervisors        & 2014-07-29        \\ \hline
  Scoping finalised                     & 2014-08-11        \\ \hline
  Research proposal draft submission    & 2014-09-01        \\ \hline
  Research proposal final submission    & 2014-09-05        \\ \hline
  Preliminary research complete         & 2014-10-16        \\ \hline
  Literature review draft submission    & 2014-10-31        \\ \hline
  Interim presentation                  & 2014-11-03        \\ \hline
  Literature review final submission    & 2014-11-07        \\ \hline
  Qualitative comparisons complete      & 2014-12-07        \\ \hline
  Data classification method complete   & 2015-01-01        \\ \hline
  Data processing recommendations due   & 2015-01-28        \\ \hline
  NeCTAR script implementation due      & 2015-02-28        \\ \hline
  Testing of pipeline on NeCTAR         & 2015-03-15        \\ \hline
  Evaluation of pipeline system         & 2015-04-01        \\ \hline
  Thesis draft submission               & 2015-05-29        \\ \hline
  Final presentation                    & 2015-06-08        \\ \hline
  Thesis final submission               & 2015-06-19        \\ \hline
\end{tabular}
\end{center}

Note that the above is simply a proposed timeline, and it is highly probable that this will be subject to change as the
project progresses.

% subsection timeline (end)

\subsection{Potential difficulties} % (fold)
\label{sub:potential_difficulties}

While we believe that most components of this project are very much feasible given the time and resources we have been
allocated so far, we have identified a small number of possible difficulties that may be encountered as the project
progresses. The most obvious difficulty so far that we have identified is the need to acquire a substantial amount of
data that we can use for both during the testing and the evaluation stages of the project. As this data will be used to
test our data classification methods and evaluate our pipeline deployed in the cloud, it will need to be diverse. By
diverse, what we mean is it must display heterogeneity in terms of its type and origin; data from many different sources
would be ideal.

Currently we have no concrete leads on the acquisition of this data, although we will look into collaboration with other
data-based research projects ongoing at Monash University. We also are yet to explore freely available data sets, such
as the Enron corpus email dataset~\cite{klimt2004introducing}, although these may definitely be taken into consideration
at a later stage in the project in the case that data acquisition proves infeasible.

% subsection potential_difficulties (end)

\subsection{Special facilities required} % (fold)
\label{sub:special_facilities_required}

As we are aiming to deploy a proof-of-concept of this pipeline, the main special facility needed access to is a cloud
solution that enables us to install and test our pipeline. For this, we have already requested access for what we are
planning to do in this project on the National eResearch Collaboration Tools and Resources (NeCTAR)
cloud~\cite{web:Nectar}. This cloud is funded by the Australian Government and available to Australian researchers in
many different disciplines.

With access to this cloud for the duration of this project, we will be able to install and perform qualitative
comparisons between the numerous realtime data processing solutions available as of now. This will assist us in making
our recommendations for the pipeline based on the classification of particular set of data.

This access to cloud resources at NeCTAR will also facilitate our later testing and evaluation stages of the project,
where we will be hoping to test the pipeline with real heterogeneous data.

% subsection special_facilities_required (end)

% section research_design (end)



\section{Expected Outcomes} % (fold)
\label{sec:expected_outcomes}

The expected outcomes of this project include both technical contributions and theoretical contributions; the technical
outcomes of the project essentially being implementations of the theoretical outcomes.

Our main theoretical contribution will be the realtime processing recommendations we produce for specific classes of
data. These recommendations will recommend specific realtime data processing technologies for use within the pipeline to
process the given data. Of course, to actually classify the data, we need to come up with some classification method.
This will be another of our theoretical contribution outcomes of this project.

Looking at the project's outcomes in terms of technical contributions, they directly relate back to the theoretical
contributions. The main technical contribution will be NeCTAR template scripts which enable the deployment of the
pipeline on the NeCTAR cloud. These scripts will be constructed based upon the recommendations produced for specific
dataset classes.

Relating back to the data classification method, we will also contribute an implementation of this so that given
datasets can be fed into the system and be classified on-the-fly. What we aim to achieve from the implementation of this
classification method is to have it as a one of the very initial stages of the pipeline, where heterogeneous data can be
fed in, have its type classified, then have a NeCTAR script constructed based upon that data classes' recommended
processing pipeline.

To summarise, the expected outcomes of this project include the following contributions:

\begin{itemize}
  \item A classification method for classifying arbitrary datasets.
  \item An implementation of this classification method for use in the deployed pipelines.
  \item Recommendations for specific classes of data on how they should be processed in realtime.
  \item NeCTAR compatible scripts allowing NeCTAR users to deploy the recommended pipelines on the NeCTAR cloud.
\end{itemize}

All of these contributions will hopefully be assembled together to make a complete pipeline generating system for any
arbitrary type of data.

% section expected_outcomes (end)


\newpage

\bibliographystyle{acm}
\bibliography{proposal}

\end{document}
