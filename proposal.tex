\documentclass[a4paper,11pt]{article}

% set up sensible margins (same as for cssethesis)
\usepackage[paper=a4paper,left=30mm,width=150mm,top=25mm,bottom=25mm]{geometry}
\usepackage{setspace}               % This is used in the title page
\usepackage{graphicx}               % This is used to load the crest in the title page
\usepackage{poltakmacros}           % Personal macros included in file 'poltakmacros.sty'
\usepackage{enumitem}               % For nested enum lists
\usepackage[font={small}]{caption}
\usepackage[hidelinks]{hyperref}
\usepackage{url}


\author{Jonathan Poltak Samosir}
\title{Honours Research Proposal}

\begin{document}

% Set up a title page
\thispagestyle{empty} % no page number on very first page
% Use roman numerals for page numbers initially
\renewcommand{\thepage}{\roman{page}}

\begin{spacing}{1.5}
\begin{center}
{\Large \bfseries
Clayton School of Information Technology\\
Monash University}

\vspace*{30mm}

\includegraphics[width=5cm]{img/MonashCrest.pdf}

\vspace*{15mm}

{\large \bfseries
Honours Research Proposal --- Semester 2, 2014
}

\vspace*{10mm}

{\LARGE \bfseries
A pipeline for the preprocessing and storage of heterogeneous big data [WORKING TITLE]
}

\vspace*{20mm}

{\large \bfseries
Jonathan Poltak Samosir [2271 3603]

\vspace*{20mm}

Supervisors: \parbox[t]{50mm}{\mbox{Dr Maria Indrawan-Santiago}\\Dr Pari Delir Haghighi}
}

\end{center}
\end{spacing}

\newpage

\tableofcontents

\newpage
% Now reset page number counter,and switch to arabic numerals for remaining page numbers
\setcounter{page}{1}
\renewcommand{\thepage}{\arabic{page}}



% Start of content

\section{Introduction} % (fold)
\label{sec:introduction}

Currently, as a society, we are generating very large amounts of data from a large range of different sources. These
sources include scientific experiments, such as the Australian Synchrotron~\cite{web:synchrotron} and The Large Hadron
Collider~\cite{web:LHC}, companies, such as Amazon~\cite{web:Amazon}, and also data generated by end users of products,
such as social networks. The rate of data that is being generated is constantly increasing, presenting major challenges
when it comes to the storage and processing of that data~\cite{bohlouli_towards_2013}. This is what is often referred to
as ``Big Data''. Out of all of this data we are faced with, often only specific parts of the data are of use for given
purposes. Hence rather than attempting to store all the new data that is being generating, often what is done, in both
academia and industry associated with big data, is the realtime processing and analysis of incoming data streams.

There are currently numerous realtime data processing frameworks that are in development and in production use, both in
industry and academia. Examples of these realtime data processing frameworks include the widely used Storm
project~\cite{web:Storm} developed at BackType and Twitter, Inc., and also the up-and-coming Spark Streaming
project~\cite{web:SparkStreaming} developed at UC Berkeley's AMPLab~\cite{web:UCBerkelyAMCLab}, both of which are
open-source projects. While there are a growing number of these projects being developed, often these projects are
designed with a particular type of data in mind, or to facilitate a particular type of data processing. For example, the
before mentioned Spark Streaming project, along with its mother project, Spark~\cite{web:Spark}, was designed for highly parallelised
data with the use-case in mind of processing data in-memory using highly iterative machine learning algorithms related
to data analytics~\cite{liu_survey_2014}.

Given these, occasionally ``narrow'', use-cases for existing data stream processing frameworks, challenges are faced in
supporting the variations in both data types and processing requirements for data processing applications. In this
research project, we aim to study the different characteristics of the data processing requirements based on the
different characteristics of the data types. The knowledge found of these characteristics will be compared with the
properties of existing solutions for big data processing.

What we propose in this document is an entire heterogeneous data processing pipeline that will facilitate the following
tasks, in sequence:

\begin{enumerate}
  \item Take in streams of data from various sources.
  \item Aggregate similar types of data.
  \item Process the data appropriately, depending on its type and the application.
  \item Store the results of the data processing on an appropriate storage medium.
\end{enumerate}

From this research project, we aim to produce a set of recommendations on choosing the various components of the
pipeline, along with recommendations on how the components should be interconnected. To complement this, we also aim to produce a design template on the
deployment of the pipeline in a cloud environment. This will be expanded on in further detail
in~\sectref{sec:expected_outcomes}.

This document will be structured as follows:\\
Discussion of the existing research and work done into this area will be
touched on in~\sectref{sec:research_context}. Our research questions, along with an outline of what we will be doing
will be outlined in~\sectref{sec:objectives}. The methodology used to achieve the deliverables of this project will be
discussed in~\sectref{sec:research_design}. Finally, we will conclude with an overview, in~\sectref{sec:expected_outcomes},
of what the expected outcomes of this project will be, along with the greater contributions this project will give back,
in the way of technological, disciplinary, and societal contributions.

% section introduction (end)



\section{Research Context} % (fold)
\label{sec:research_context}



% section research_context (end)



\section{Objectives} % (fold)
\label{sec:objectives}

\subsection{Research questions} % (fold)
\label{sub:research_questions}

The following research questions will be the main focus of our project:

\begin{enumerate}
  \item What classification methods can we best use to classify arbitrary data?
  \item How the data arriving in the pipeline be preprocessed and structured to adhere to the interface of the appropriate
   storage system?
  \item How can existing data stream processing solutions be used or be altered for use within this pipeline?
\end{enumerate}

% subsection research_questions (end)


\subsection{Research aims} % (fold)
\label{sub:research_aims}

The main aim or goal of this research project is to develop a set of recommendations that can lead to the creation of
this data stream processing pipeline. While we do not aim to have a fully usable, production-ready piece of software as a
deliverable, we want to at least have a proof-of-concept working in the National eResearch Collaboration Tools and Resources
(NeCTAR) cloud~\cite{web:Nectar}.

% subsection research_aims (end)

% section objectives (end)



\section{Research Design} % (fold)
\label{sec:research_design}

\subsection{Methodology} % (fold)
\label{sub:methodology}



% subsection methodology (end)

\subsection{Proposed thesis chapter headings} % (fold)
\label{sub:proposed_thesis_chapter_headings}

The proposed structure of the thesis is as follows:

\begin{enumerate}
  \item Introduction
  \begin{enumerate}[label*=\arabic*.]
    \item Overview
    \item Background
    \item Research problem
    \item Research questions
    \item Research scope
    \item Conclusion and thesis structure
  \end{enumerate}
  \item Literature Review
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Definition of terms
    \item Big data in industry and academia
    \item Batch data processing
    \item Overview of batch data processing technologies
    \item Realtime data processing
    \item Overview of realtime data processing technologies
    \item Disruptive research in big data
    \item Conclusion
  \end{enumerate}
  \item Streaming Data Preprocessing Pipeline Model
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Need for preprocessing pipeline
    \item Overview of pipeline
    \item Usage of pipeline
    \item Conclusion
  \end{enumerate}
  \item Research Method and Implementation
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Chosen research method
    \item Data classification method
    \item Data processing technologies for pipeline
    \item Implementation of pipeline in NeCTA cloud
    \item Formulation of pipeline recommendations
    \item Conclusion
  \end{enumerate}
  \item Discussion and Evaluation
  \begin{enumerate}[label*=\arabic*.]
    \item Introduction
    \item Further methods for data classification
    \item Future of big data research
    \item Evaluation of project
    \item Conclusion
  \end{enumerate}
  \item Conclusion
  \begin{enumerate}[label*=\arabic*.]
    \item Overview
    \item Research contributions
    \item Research limitations
    \item Future research
  \end{enumerate}
  \item Reference List
  \item Appendices
\end{enumerate}

% subsection proposed_thesis_chapter_headings (end)

\subsection{Timetable} % (fold)
\label{sub:timetable}



% subsection timetable (end)

\subsection{Potential difficulties} % (fold)
\label{sub:potential_difficulties}

While we believe that most components of this project are very much feasible given the time and resources we have
allocated so far, we have identified a small number of possible difficulties that may be encountered as the project
progresses. The most obvious difficulty so far that we have identified is the possibility of acquiring a substantial
amount of data that we can use for both testing and during the evaluation stages of the project. As this data will be
used to test our data classification methods and evaluate our pipeline deployed in the cloud, it will need to be
diverse. By diverse, what we mean is it must display heterogeneity in terms of its type and origin; data from many
different sources would be ideal.

Currently we have no concrete leads on the acquisition of this data, although we will look into collaboration with other
data-based research projects ongoing at Monash. We also are yet to explore freely available data sets, such as the Enron
corpus email dataset~\cite{klimt2004introducing}, although these may definitely be taken into
consideration at a later stage in the project in the case that data acquisition proves infeasible.

% subsection potential_difficulties (end)

\subsection{Special facilities required} % (fold)
\label{sub:special_facilities_required}

As we are aiming to deploy a proof-of-concept of this pipeline, the main special facility needed access to is a cloud solution
that enables us to install and test our pipeline. For this, we have already requested access for what we are planning to do
in this project on the National eResearch Collaboration Tools and Resources (NeCTAR) cloud~\cite{web:Nectar}. This cloud
is funded by the Australian Government and available to Australian researchers in many different disciplines.

With
access to this cloud for the duration of this project, we will be able to install and perform qualitative comparisons
between the numerous realtime data processing solutions available as of now. This will assist us in making our recommendations
for the pipeline based on the classification of particular set of data.

% subsection special_facilities_required (end)

% section research_design (end)



\section{Expected Outcomes} % (fold)
\label{sec:expected_outcomes}

% section expected_outcomes (end)


\newpage

\bibliographystyle{acm}
\bibliography{proposal}

\end{document}
